{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for Stock Market Prediction\n",
    "Author: Antonio Stark, Sasha Pukhova, Frank Looi, Precious Enharo\n",
    "\n",
    "Kaggle challenge: https://www.kaggle.com/aaron7sun/stocknews\n",
    "Kaggle article: https://www.kaggle.com/rahulvarma9595/nlp-for-stock-market-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is 1989 data points with 27 features\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('Combined_News_DJIA.csv')\n",
    "\n",
    "print('data is %d data points with %d features'%(data.shape[0],data.shape[1]))\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "b'55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay'\n",
      "\n",
      "Cleaned text:\n",
      "55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay\n",
      "\n",
      "Punctuations removed:\n",
      "55 pyramids as large as the Luxor stacked into a megacity pyramid in Tokyo Bay\n",
      "\n",
      "Lowercase:\n",
      "55 pyramids as large as the luxor stacked into a megacity pyramid in tokyo bay\n",
      "\n",
      "Numbers removed:\n",
      " pyramids as large as the luxor stacked into a megacity pyramid in tokyo bay\n"
     ]
    }
   ],
   "source": [
    "## create copy of original dataframe\n",
    "dataClean = data.copy()\n",
    "\n",
    "# news header you want to test\n",
    "## (2,5) is interesting to see how \"Al-Qa'eda\" gets transferred\n",
    "## (4,3) is interesting to see how numbers are encoded\n",
    "## (2,15) is interesting to see how both numbers ('55') and hyphens ('mega-city') are encoded\n",
    "## (1988,24) gives a bug for replacing numbers and removing stop words\n",
    "tester = (2,15)\n",
    "\n",
    "for i in range(2,data.shape[1]):\n",
    "    if i==tester[1]:\n",
    "        print('Original text:')\n",
    "        print(dataClean.iloc[tester[0],i])\n",
    "    \n",
    "    # Data cleaning\n",
    "    \n",
    "    ## remove 'b'' at the start and ''' at the end\n",
    "    dataClean.iloc[:,i]=dataClean.iloc[:,i].str.strip(\"b'\")\n",
    "    if i==tester[1]:\n",
    "        print('\\nCleaned text:')\n",
    "        print(dataClean.iloc[tester[0],i])\n",
    "    \n",
    "    ## remove punctuation\n",
    "    dataClean.iloc[:,i]=dataClean.iloc[:,i].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    if i==tester[1]:\n",
    "        print('\\nPunctuations removed:')\n",
    "        print(dataClean.iloc[tester[0],i])\n",
    "        \n",
    "\n",
    "    ## make lowercase\n",
    "    dataClean.iloc[:,i]=dataClean.iloc[:,i].str.lower()\n",
    "    if i==tester[1]:\n",
    "        print('\\nLowercase:')\n",
    "        print(dataClean.iloc[tester[0],i])\n",
    "    \n",
    "    # remove numbers\n",
    "    dataClean.iloc[:,i]=dataClean.iloc[:,i].str.translate(str.maketrans('', '', string.digits))\n",
    "    if i==tester[1]:\n",
    "        print('\\nNumbers removed:')\n",
    "        print(dataClean.iloc[tester[0],i])\n",
    "    \n",
    "#No need to do word tokenisation, stemming, lemmatization/ canonicalization in this model\n",
    "# This is because words end up being broken down in the vectoriser\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train/test sets by date\n",
    "\n",
    "data_Vectorized = dataClean\n",
    "\n",
    "data_Vectorized.Date = pd.to_datetime(dataClean[\"Date\"])\n",
    "train = data_Vectorized.loc[data_Vectorized.Date < datetime.datetime(2015, 1, 2)]\n",
    "\n",
    "y_train = train.Label\n",
    "X_train = train.drop(['Date', 'Label'], axis=1)\n",
    "\n",
    "\n",
    "test = data_Vectorized.loc[data_Vectorized.Date >= datetime.datetime(2015, 1, 2)]\n",
    "y_test = test.Label\n",
    "X_test = test.drop(['Date', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the TF-IDF Vectoriser on the combined list of headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "for row in range(0,len(X_train.index)):\n",
    "    headlines.append(' '.join(str(x) for x in X_train.iloc[row,0:25]))\n",
    "    \n",
    "testheadlines = []\n",
    "for row in range(0,len(X_test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in X_test.iloc[row,0:25]))\n",
    "    \n",
    "    \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words='english') #smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')\n",
    "\n",
    "X_train = vectorizer.fit_transform(headlines)\n",
    "X_test = vectorizer.transform(testheadlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['RF','XGB','LogReg','MLP']\n",
    "\n",
    "def predModel(X_train, y_train, X_test, y_test, modelType=models[0]):\n",
    "    if modelType not in models:\n",
    "        print('Error: model not in predefined list')\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if modelType == models[0]:\n",
    "        rf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "        rf.fit(X_train, y_train)        \n",
    "        end_time = time.time()\n",
    "        # predict for X_test\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "    elif modelType == models[1]:\n",
    "        xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "        xgb.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        # predict for X_test\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        \n",
    "    elif modelType == models[2]:\n",
    "        lg = LogisticRegression(penalty='l1', C=1.5, solver='liblinear', max_iter=100, n_jobs=-1)\n",
    "        lg.fit(X_train, y_train)\n",
    "        end_time = time.time()        \n",
    "        # predict for X_test\n",
    "        y_pred = lg.predict(X_test)\n",
    "        \n",
    "    elif modelType == models[3]:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        # predict for X_test\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print('Accuracy for model %s is: %.2f'%(modelType,accuracy_score(y_test,y_pred)))\n",
    "    print('ROC AUC for model %s is: %.2f'%(modelType,roc_auc_score(y_test, y_pred)))\n",
    "    print('Model training time is %.3f seconds'%(end_time-start_time))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model RF is: 0.46\n",
      "ROC AUC for model RF is: 0.46\n",
      "Model training time is 0.157 seconds\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.46      0.46       186\n",
      "           1       0.47      0.47      0.47       192\n",
      "\n",
      "    accuracy                           0.46       378\n",
      "   macro avg       0.46      0.46      0.46       378\n",
      "weighted avg       0.46      0.46      0.46       378\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 85 101]\n",
      " [102  90]]\n"
     ]
    }
   ],
   "source": [
    "predModel(X_train, y_train, X_test, y_test, modelType='RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model XGB is: 0.46\n",
      "ROC AUC for model XGB is: 0.45\n",
      "Model training time is 15.099 seconds\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.26      0.32       186\n",
      "           1       0.48      0.65      0.55       192\n",
      "\n",
      "    accuracy                           0.46       378\n",
      "   macro avg       0.45      0.45      0.43       378\n",
      "weighted avg       0.45      0.46      0.44       378\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 48 138]\n",
      " [ 67 125]]\n"
     ]
    }
   ],
   "source": [
    "predModel(X_train, y_train, X_test, y_test, modelType='XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model LogReg is: 0.51\n",
      "ROC AUC for model LogReg is: 0.50\n",
      "Model training time is 0.073 seconds\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.06      0.11       186\n",
      "           1       0.51      0.94      0.66       192\n",
      "\n",
      "    accuracy                           0.51       378\n",
      "   macro avg       0.49      0.50      0.38       378\n",
      "weighted avg       0.49      0.51      0.39       378\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 11 175]\n",
      " [ 12 180]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    }
   ],
   "source": [
    "predModel(X_train, y_train, X_test, y_test, modelType='LogReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model MLP is: 0.51\n",
      "ROC AUC for model MLP is: 0.50\n",
      "Model training time is 0.163 seconds\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       186\n",
      "           1       0.51      1.00      0.67       192\n",
      "\n",
      "    accuracy                           0.51       378\n",
      "   macro avg       0.25      0.50      0.34       378\n",
      "weighted avg       0.26      0.51      0.34       378\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[  0 186]\n",
      " [  0 192]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predModel(X_train, y_train, X_test, y_test, modelType='MLP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
